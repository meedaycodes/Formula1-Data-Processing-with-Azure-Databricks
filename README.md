# Formula1-Data-Processing-with-Azure-Databricks
Tools- Used: Azure Databricks, Databricks compute clusters, Databricks Notebooks, Azure Gen-2 Datalake storage, DeltaLake File format, Pyspark, Azure data Factory[Triggers, Linked Services], Power-BI
- The formula-1 historic data used for this project can be downloaded as a zipfile or using the Ergast API 
### Objectives 
  1- To develop an highly scallable data pipeline with the capability of handling both Incremental and Full refresh data load operations.
  2- Build dataframes stored delta file format that supports different queries as the need may arise
### Milestone -1
- The first step was to create an Azure Resource group with a subscription via the azure portal, all other azure resource services (databricks, storage account, Azure data factory e.t.c) used for this project was tied to the created resource group
- 
